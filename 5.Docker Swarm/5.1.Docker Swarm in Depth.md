# Docker Swarm in Depth

**Docker Swarm** bo‘yicha ushbu keng qamrovli qo‘llanmaga xush kelibsiz. Ushbu maqolada biz **Docker Swarm** va uning asosiy komponentlariga e’tibor qaratgan holda ilg‘or **Docker** tushunchalariga chuqur kirib boramiz. Maqsad — sizga mustahkam **container orchestration cluster**ni qanday yaratish va boshqarishni puxta tushunishga yordam berishdir.

**Docker Swarm** bitta **Docker host**da konteynerlarni ishga tushirish cheklovlarini bartaraf etish uchun ishlab chiqilgan. Bu odatda **development** yoki **testing** uchun yetarli bo‘ladi, ammo **production** muhitida bu xavfli. Bitta **host**ga tayanish **single point of failure** muammosini keltirib chiqaradi — agar o‘sha **host** ishlamay qolsa, barcha **container**lar va **application**lar mavjud bo‘lmay qoladi. **Docker Swarm** bu xavfni bir nechta **Docker machine**larni klasterga birlashtirish orqali kamaytiradi, natijada yuqori **availability** va **load balancing** ta’minlanadi.

**Docker Swarm**ni sozlash uchun, **Docker** o‘rnatilgan bir nechta **host**larga ega ekanligingizga ishonch hosil qiling. Ulardan birini **Swarm Manager** (ko‘pincha **master** deb ataladi) sifatida belgilang, qolganlari esa **worker** sifatida ishlaydi. **Manager node**da quyidagi buyruqni ishga tushiring:

```bash
docker swarm init
```

Natijada, chiqishda **join command** ko‘rsatiladi. Ushbu buyruqni har bir **worker node**da bajaring, shunda ular **swarm**ga qo‘shiladi. Barcha **worker**lar qo‘shilgach, ular birgalikda **nodes** deb ataladi va sizning **cluster**ingiz **service**larni joylashtirishga tayyor bo‘ladi.

## Manager Nodes and Raft Consensus

**Manager node** **swarm cluster** ichida muhim rol o‘ynaydi; u **swarm**ni ishga tushiradi, **cluster state**ni saqlaydi va **container**lar hamda **service**larning taqsimotini boshqaradi. Bitta **manager node**ni ishlatish mumkin, ammo bu xavf tug‘diradi: agar yagona **manager** ishdan chiqsa, siz **cluster management** imkoniyatlarini yo‘qotasiz.

**Production cluster**lar uchun **Docker Swarm** bir nechta **manager node**larni qo‘llab-quvvatlaydi. Biroq, har bir vaqt momentida faqat bitta **manager** **leader** sifatida ishlaydi va asosiy boshqaruv qarorlarini qabul qiladi. Har qanday o‘zgarish kiritishdan oldin, **leader** **manager**lar ko‘pchiligidan **consensus** oladi, bu esa **cluster state**ning izchilligini saqlaydi va **swarm**ni buzishi mumkin bo‘lgan bir tomonlama o‘zgarishlarning oldini oladi.

**Docker Swarm** **manager node**lar orasida izchillikni ta’minlash uchun **Raft consensus algorithm**dan foydalanadi. Ushbu algoritm quyidagicha ishlaydi:

- Har bir **manager node** tasodifiy **timer**ni ishga tushiradi.  
- **Timer** birinchi bo‘lib tugagan **manager** o‘z tengdoshlariga **leadership request** yuboradi.  
- Boshqa **manager**lar o‘z **vote**lari bilan javob berishadi.  
- Zarur **vote**larni to‘plagan **manager** **leader** sifatida saylanadi va o‘z holatini tasdiqlovchi davriy bildirishnomalar (**heartbeat**) yuborishni boshlaydi.  
- Agar bu bildirishnomalar to‘xtasa — nosozlik yoki **network issue** sababli — yangi **election** jarayoni boshlanadi.

Har bir **manager node** butun **cluster** haqidagi ma’lumotni o‘z ichiga olgan **Raft database**ning lokal nusxasini saqlaydi. O‘zgarishlar kiritilayotganda (masalan, **worker** qo‘shish yoki **service** yaratish), **leader** bu o‘zgarishlarni **commit** qilishdan oldin **manager node**lar ko‘pchiligidan **vote** olishi kerak (**quorum**ga erishish). Ushbu jarayon barcha o‘zgarishlarning **cluster** tomonidan izchil tarzda tasdiqlanishini ta’minlaydi.

## Best Practices with Manager Nodes

**Docker Swarm**dagi har bir qaror, **Raft algorithm** asosida, **manager node**lardan ko‘pchilik **vote**ni talab qiladi. Bu ko‘pchilik **quorum** deb ataladi. Masalan:

- Agar **cluster**da 3 ta **manager node** bo‘lsa, **quorum** = 2.  
- Agar **cluster**da 5 ta **manager node** bo‘lsa, **quorum** = 3.  
- Agar **cluster**da 7 ta **manager node** bo‘lsa, **quorum** = 4.  

**Quorum**ni hisoblash uchun oddiy formula:  
  **Quorum = floor(Total Managers ÷ 2) + 1**

**Docker** 7 tadan ortiq **manager node** ishlatishni tavsiya etmaydi, chunki bu sondan ortiq qo‘shilgan **node**lar **scalability** yoki **performance**ni oshirmaydi.

Shuningdek, **fault tolerance** tushunchasi ham juda muhimdir. **Fault tolerance** — bu **cluster** normal ishlashni davom ettirishi mumkin bo‘lgan maksimal **manager node failure**lar sonini bildiradi. Odatda u quyidagicha hisoblanadi:  
  **Fault Tolerance = floor((n - 1) / 2)**  

Misol uchun:

- 3 ta **manager** bilan: 1 ta **failure**ga chidamli.  
- 5 ta **manager** bilan: 2 ta **failure**ga chidamli.  
- 7 ta **manager** bilan: 3 ta **failure**ga chidamli.  

**Cluster**ni sozlashda har doim **manager node**lar sonini toq qilib tanlang (masalan, 3, 5 yoki 7). Bu ayniqsa **network partition** holatlarida muhim. Masalan, 6 ta **manager** 3 tadan ikkita guruhga bo‘linsa, hech biri **quorum** (4) ga erisha olmaydi; lekin 7 ta **manager** 4 va 3 tadan guruhlarga bo‘linsa, 4 ta bo‘lgan guruh hali ham **cluster**ni boshqara oladi.

> **Cluster**ni loyihalashda, har doim kamida bitta **backup manager** mavjudligiga ishonch hosil qiling, bu nosozlik yuz berganda **quorum**ni tezda tiklash imkonini beradi.

## Handling Cluster Failures

Tasavvur qiling, sizda uchta **manager node** va beshta **worker node** mavjud bo‘lib, ular sizning **web application**ingizning bir nechta **instance**larini ishga tushirgan. Hatto **manager**larda muammolar yuzaga kelsa ham, **worker node**lar **application**ni ishlashda davom etadi va **service availability**ni ta’minlaydi.

Uchta **manager**li konfiguratsiyada **quorum** uchun 2 ta **manager** talab qilinadi. Agar ikki **manager** bir vaqtning o‘zida ishdan chiqsa, **swarm** o‘zining **management capabilities**ini yo‘qotadi. Ammo sizning **service**laringiz ishlashda davom etadi, chunki **worker node**lar hali ham faol. Bunday holatlarda siz yangi **worker**larni qo‘sha olmaysiz yoki **service**larni yangilay olmaysiz, to **quorum** tiklanmaguncha.

> **Warning**  
> Agar **quorum** yo‘qolsa, tavsiya etilgan chora — ishdan chiqqan **manager node**larni qayta ishga tushirishdir.  
> Agar faqat bitta **manager** mavjud bo‘lsa, quyidagi buyruq yordamida yangi **cluster**ni majburan yaratishingiz kerak bo‘ladi.

Joriy **node**ni yagona **manager** sifatida belgilab, yangi **cluster**ni majburan yaratish uchun quyidagi buyruqni bajaring:

```bash
docker swarm init --force-new-cluster
```

Ushbu buyruq mavjud **service configuration**lar va **task**larni saqlagan holda yangi **cluster** yaratadi. **Worker node**lar **swarm** tarkibida qoladi va **service continuity**ni ta’minlaydi. Keyinchalik, qo‘shimcha **node**larni quyidagi buyruq yordamida **manager** sifatida **promote** qilishingiz mumkin:

```bash
docker node promote <Node>
```

## Manager Nodes as Workers

Odatiy holatda, **manager node**lar ham **worker node**lar sifatida **task**larni bajaradi. **Production** muhitida esa **performance**ni optimallashtirish uchun **manager node**larni faqat **cluster management** uchun ajratib qo‘yish tavsiya etiladi. **Manager node**ni oddiy **service**larni bajarishdan to‘xtatish (ya’ni uni **drain** holatiga o‘tkazish) uchun quyidagi buyruqdan foydalaning:

```bash
docker node update --availability drain <Node>
```

**Testing** yoki **development** muhitlarida, bitta **node**li **swarm** bir vaqtning o‘zida ham **manager**, ham **worker** sifatida ishlashi mumkin.

## Conclusion

**Docker Swarm**’ning **architecture**si, **manager node**larning roli va **fault tolerance** bo‘yicha eng yaxshi amaliyotlarni chuqurroq tushungan holda, endi siz bardoshli **Docker Swarm cluster**ni loyihalash va uni boshqarishga yaxshiroq tayyorsiz.
